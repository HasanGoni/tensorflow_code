{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, concatenate,BatchNormalization,Conv2D, Add, Activation,MaxPool2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape= [1], name = 'Wide_Input')\n",
    "input_b = Input(shape= [1], name = 'Deep_Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = Dense(units= 30, activation = 'relu')(input_b)\n",
    "layer_2 = Dense(units = 30, activation = 'relu')(layer_1)\n",
    "\n",
    "concat = concatenate([input_a, layer_2])\n",
    "output = Dense(1, name = 'Outputt')(concat)\n",
    "\n",
    "\n",
    "aux_out = Dense(1, name = 'Aux_out')(layer_2)\n",
    "\n",
    "model = Model(inputs = [input_a, input_b], outputs = [output, aux_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from the Model base class\n",
    "class WideAndDeepModel(Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        '''initializes the instance attributes'''\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = Dense(units, activation=activation)\n",
    "        self.hidden2 = Dense(units, activation=activation)\n",
    "        self.main_output = Dense(1)\n",
    "        self.aux_output = Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''defines the network architecture'''\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        \n",
    "        return main_output, aux_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the model\n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBlock(Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(IdentityBlock, self).__init__(name= '')\n",
    "        \n",
    "        self.conv1 = Conv2D(filters, kernel_size, padding= 'same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        \n",
    "        self.conv2 =  Conv2D(filters, kernel_size, padding = 'same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        \n",
    "        self.act = Activation('relu')# YOUR CODE HERE\n",
    "        self.add = Add()\n",
    "        \n",
    "        \n",
    "    def call(self, inputs_tensor):\n",
    "        x = self.conv1(inputs_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.add([x, inputs_tensor])\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(64, 7, padding = 'same')\n",
    "        self.bn = BatchNormalization()\n",
    "        self.act = Activation('relu')\n",
    "        \n",
    "        self.max_pool = MaxPool2D((3,3))\n",
    "        \n",
    "        self.id1a = IdentityBlock(64,3)\n",
    "        self.id2a = IdentityBlock(64,3)\n",
    "        \n",
    "        self.global_pool= GlobalAveragePooling2D()\n",
    "        \n",
    "        self.classifier = Dense(num_classes, activation = 'softmax')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.id1a(x)\n",
    "        x = self.id2a(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to normalize the images and return (image, label) pairs.\n",
    "def preprocess(features):\n",
    "    return tf.cast(features['image'], tf.float32) / 255., features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ./data/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
      "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e068a418334d0fa602355e25a04e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Completed...'), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to ./data/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('mnist', split=tfds.Split.TRAIN, data_dir='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.1801 - accuracy: 0.9568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe620d81af0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "resnet.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
    "        super(Block, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.repetitions = repetitions\n",
    "        \n",
    "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
    "        for i in range(self.repetitions):\n",
    "            \n",
    "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
    "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(self.filters, self.kernel_size, activation = 'relu',padding= 'same')\n",
    "        \n",
    "        # Define the max pool layer that will be added after the Conv2D blocks\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(pool_size), strides=strides)\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        # access the class's conv2D_0 layer\n",
    "        conv2D_0 = self.conv2D_0\n",
    "        \n",
    "        # Connect the conv2D_0 layer to inputs\n",
    "        x = conv2D_0(inputs)\n",
    "\n",
    "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
    "        for i in range(1,self.repetitions):\n",
    "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
    "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
    "            \n",
    "            # Use the conv2D_i and connect it to the previous layer\n",
    "            x = conv2D_i(x)\n",
    "\n",
    "        # Finally, add the max_pool layer\n",
    "        max_pool = self.max_pool(x)\n",
    "        \n",
    "        return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVGG(Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyVGG, self).__init__()\n",
    "        \n",
    "        self.block_a = Block(64, 3,2)\n",
    "        self.block_b = Block(128, 3, 2)\n",
    "        self.block_c = Block(256, 3, 3)\n",
    "        self.block_d = Block(512, 3, 3)\n",
    "        self.block_e = Block(512, 3, 3)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = tf.keras.layers.Dense(256, activation = 'relu')\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.block_a(inputs)\n",
    "        x = self.block_b(x)   \n",
    "        x = self.block_c(x) \n",
    "        x = self.block_d(x) \n",
    "        x = self.block_e(x) \n",
    "        x = self.flatten(x) \n",
    "        x = self.fc(x) \n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data/')\n",
    "\n",
    "# Initialize VGG with the number of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = MyVGG(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "def preprocess(features):\n",
    "    # Resize and normalize\n",
    "    image = tf.image.resize(features['image'], (224, 224))\n",
    "    return tf.cast(image, tf.float32) / 255., features['label']\n",
    "\n",
    "# Apply transformations to dataset\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "# Compile with losses and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "727/727 [==============================] - 731s 1s/step - loss: 0.6885 - accuracy: 0.5493\n",
      "Epoch 2/10\n",
      "727/727 [==============================] - 725s 997ms/step - loss: 0.6649 - accuracy: 0.6182\n",
      "Epoch 3/10\n",
      "727/727 [==============================] - 724s 996ms/step - loss: 0.6392 - accuracy: 0.6524\n",
      "Epoch 4/10\n",
      "727/727 [==============================] - 723s 994ms/step - loss: 0.6180 - accuracy: 0.6717\n",
      "Epoch 5/10\n",
      "727/727 [==============================] - 725s 997ms/step - loss: 0.6024 - accuracy: 0.6820\n",
      "Epoch 6/10\n",
      "727/727 [==============================] - 724s 996ms/step - loss: 0.5907 - accuracy: 0.6910\n",
      "Epoch 7/10\n",
      "727/727 [==============================] - 722s 993ms/step - loss: 0.5814 - accuracy: 0.6992\n",
      "Epoch 8/10\n",
      "727/727 [==============================] - 728s 1s/step - loss: 0.5733 - accuracy: 0.7052\n",
      "Epoch 9/10\n",
      "727/727 [==============================] - 738s 1s/step - loss: 0.5661 - accuracy: 0.7098\n",
      "Epoch 10/10\n",
      "727/727 [==============================] - 740s 1s/step - loss: 0.5596 - accuracy: 0.7148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe619a99940>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the custom VGG model\n",
    "vgg.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
